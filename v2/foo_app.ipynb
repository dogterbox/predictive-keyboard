{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:38.849352Z",
     "start_time": "2019-06-26T13:00:38.844367Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(fname, key_int=False):\n",
    "    with open(fname, 'r') as file:\n",
    "        data = file.read()\n",
    "        json_data = json.loads(data)\n",
    "        \n",
    "        if not key_int:\n",
    "            return json_data\n",
    "        \n",
    "        json_data = {int(key): value for key, value in json_data.items()}\n",
    "        return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:38.860325Z",
     "start_time": "2019-06-26T13:00:38.851347Z"
    }
   },
   "outputs": [],
   "source": [
    "CHARS = read_json('CHARS.json')\n",
    "CHAR_INDICES = read_json('CHAR_INDICES.json')\n",
    "INDICES_CHAR = read_json('INDICES_CHAR.json', key_int=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:44.491437Z",
     "start_time": "2019-06-26T13:00:38.862350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "MODEL = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictive Keyboad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:44.964750Z",
     "start_time": "2019-06-26T13:00:44.492434Z"
    }
   },
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import DEFAULT_DICT_TRIE\n",
    "from pythainlp import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:44.973720Z",
     "start_time": "2019-06-26T13:00:44.965742Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_input(text, look_back=40):\n",
    "    text = text[-look_back:]  # select lasted word\n",
    "    text = text.lower()  # to lower-case\n",
    "    x = np.zeros((1, look_back, len(CHARS)))\n",
    "    for t, char in enumerate(text):\n",
    "        if char in CHAR_INDICES:\n",
    "            x[0, t, CHAR_INDICES[char]] = 1.\n",
    "        else:\n",
    "            pass\n",
    "    return x\n",
    "\n",
    "\n",
    "def sample(arr, top_n=1):\n",
    "    '''Return index of max value on top_n'''\n",
    "    arr2 = arr.copy()\n",
    "    indices = []\n",
    "    \n",
    "    for _ in range(top_n):\n",
    "        index = np.argmax(arr2)\n",
    "        indices.append(index)\n",
    "        arr2[index] = -9999\n",
    "    return indices\n",
    "\n",
    "\n",
    "def merge_token(tokens):\n",
    "    tokens = tokens[:-2] + [tokens[-2] + tokens[-1]]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def predict_completion(text, _):\n",
    "    original_text = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = MODEL.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = INDICES_CHAR[next_index]\n",
    "\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        if next_char == '|':\n",
    "            return completion.replace('|', '')  # remove '|' \n",
    "        \n",
    "        \n",
    "def predict_completions(text, n=3, mingen=2):\n",
    "    completions = []\n",
    "    x = prepare_input(text)\n",
    "    preds = MODEL.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    for index in next_indices:\n",
    "        next_char = INDICES_CHAR[index]\n",
    "        next_next_string = predict_completion(text[1:] + next_char, mingen)  # string after next char\n",
    "        next_string = next_char + next_next_string  # next string\n",
    "        completions.append(next_string)\n",
    "    return completions\n",
    "\n",
    "\n",
    "def prepare_text(text, merge=True):\n",
    "    tokens = word_tokenize(text, engine='newmm')\n",
    "    if merge is True:\n",
    "        tokens = merge_token(tokens)\n",
    "    return '|'.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:45.009634Z",
     "start_time": "2019-06-26T13:00:44.974718Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_indict(last_token, preds):\n",
    "    result = {\n",
    "        'correct': [],\n",
    "        'predictive': []\n",
    "    }\n",
    "    for pred in preds:\n",
    "        token = last_token + pred\n",
    "        if token in DEFAULT_DICT_TRIE:\n",
    "            result['correct'].append(token)\n",
    "        elif (last_token in DEFAULT_DICT_TRIE) and (pred in DEFAULT_DICT_TRIE):\n",
    "            result['predictive'].append(pred)\n",
    "        else:\n",
    "            pass\n",
    "    return result['correct'], result['predictive']\n",
    "\n",
    "\n",
    "def del_subset(tokens):\n",
    "    result = []\n",
    "    for t in tokens:\n",
    "        is_subset = False\n",
    "        for token in tokens:\n",
    "            if t in token and t != token:\n",
    "                is_subset = True\n",
    "                break\n",
    "        if is_subset is False:\n",
    "            result.append(t)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:45.020597Z",
     "start_time": "2019-06-26T13:00:45.012617Z"
    }
   },
   "outputs": [],
   "source": [
    "# input texts\n",
    "\n",
    "texts = [\n",
    "    '‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏∂‡πà',\n",
    "    '‡πÄ‡∏à‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡πÜ ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç',\n",
    "    '‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤',\n",
    "    '‡∏™‡∏∏‡∏ô‡∏±‡∏Ç ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏°‡∏µ‡πÄ‡∏Ç‡∏µ‡πâ‡∏¢‡∏ß‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏™‡∏°‡∏û‡∏±',\n",
    "    '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±',\n",
    "    \"'‡πÅ‡∏°‡∏ßüê±' ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏•‡∏π‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏° ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ï‡∏£\",\n",
    "    '‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ñ‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏µ‡∏ô ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ä‡∏ô‡∏¥‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:00:55.285717Z",
     "start_time": "2019-06-26T13:00:45.022621Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  ‡πÉ‡∏ô‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏±‡∏á‡∏Ñ‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏∂‡πà\n",
      "Correct:  ['‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡∏∂‡πà‡∏á']\n",
      "Predictive:  []\n",
      "\n",
      "Text:  ‡πÄ‡∏à‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡πÜ ‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç\n",
      "Correct:  []\n",
      "Predictive:  ['‡∏™‡∏£', '‡∏û‡∏£', '‡∏Ç‡∏≤']\n",
      "\n",
      "Text:  ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤\n",
      "Correct:  ['‡∏Å‡∏≤‡∏•', '‡∏Å‡∏≤‡∏¢', '‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£']\n",
      "Predictive:  []\n",
      "\n",
      "Text:  ‡∏™‡∏∏‡∏ô‡∏±‡∏Ç ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏°‡∏µ‡πÄ‡∏Ç‡∏µ‡πâ‡∏¢‡∏ß‡∏ä‡∏ô‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏™‡∏°‡∏û‡∏±\n",
      "Correct:  ['‡∏û‡∏±‡∏Å', '‡∏û‡∏±‡∏î', '‡∏û‡∏±‡∏ô', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏û‡∏±‡∏á', '‡∏û‡∏±‡∏ä']\n",
      "Predictive:  []\n",
      "\n",
      "Text:  ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±\n",
      "Correct:  ['‡∏´‡∏•‡∏±‡∏ö', '‡∏´‡∏•‡∏±‡∏î', '‡∏´‡∏•‡∏±‡∏Å', '‡∏´‡∏•‡∏±‡πà‡∏ô', '‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á']\n",
      "Predictive:  []\n",
      "\n",
      "Text:  '‡πÅ‡∏°‡∏ßüê±' ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á‡∏•‡∏π‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏° ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ï‡∏£\n",
      "Correct:  ['‡∏ï‡∏£‡∏á', '‡∏ï‡∏£‡∏∞', '‡∏ï‡∏£‡∏π', '‡∏ï‡∏£‡∏°']\n",
      "Predictive:  []\n",
      "\n",
      "Text:  ‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ñ‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏à‡∏µ‡∏ô ‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ä‡∏ô‡∏¥‡∏î‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà\n",
      "Correct:  []\n",
      "Predictive:  ['‡∏≠‡∏°', '‡∏Å‡∏≤‡∏£', '‡∏á‡∏≤‡∏ô', '‡∏ß‡∏á']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# correct and predictive word\n",
    "\n",
    "for text in texts:\n",
    "    text1 = prepare_text(text, False)\n",
    "    text2 = prepare_text(text, True)\n",
    "    \n",
    "    completions1 = predict_completions(text1, 10)\n",
    "    completions2 = predict_completions(text2, 10)\n",
    "    \n",
    "    correct1, predictive1 = select_indict(text1.split('|')[-1], completions1)\n",
    "    correct2, predictive2 = select_indict(text2.split('|')[-1], completions2)\n",
    "\n",
    "    correct = del_subset(correct1 + correct2)\n",
    "    predictive = del_subset(predictive1 + predictive2)\n",
    "    \n",
    "    print('Text: ', text)\n",
    "    print('Correct: ', correct)\n",
    "    print('Predictive: ', predictive, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
